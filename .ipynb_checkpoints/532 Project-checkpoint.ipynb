{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_sample(X_train, y_train, classes, samples_per_class=6):\n",
    "#     \"\"\"visualize some samples in the training datasets \"\"\"\n",
    "#     num_classes = len(classes)\n",
    "#     for y, cls in enumerate(classes):\n",
    "#         idxs = np.flatnonzero(y_train == y) # get all the indexes of cls\n",
    "#         idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "#         for i, idx in enumerate(idxs): # plot the image one by one\n",
    "#             plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n",
    "#             plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "#             plt.imshow(X_train[idx].astype('uint8'))\n",
    "#             plt.axis('off')\n",
    "#             if i == 0:\n",
    "#                 plt.title(cls)\n",
    "#     plt.show()\n",
    "# visualize(X, y, classes)\n",
    "# classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        X = dict[b'data']\n",
    "        y = dict[b'labels']\n",
    "        # Convert labels from list to array\n",
    "        y = np.asarray(y)\n",
    "#         X = X_train.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5']\n",
    "X = np.zeros([50000, 3072])\n",
    "y = np.zeros(50000)\n",
    "for i in range(len(names)):\n",
    "    X[i*10000:(i+1)*10000,:],y[i*10000:(i+1)*10000] = load_batch(names[i])\n",
    "print('Training data shape: ', X.shape)\n",
    "print('Training label shape: ', y.shape)\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test,y_test = load_batch('test_batch')\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test label shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_image = np.mean(X_train, axis=0)\n",
    "# mean_image.shape\n",
    "# X_train = X_train -mean_image\n",
    "# X_test = X_test -mean_image\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Square Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(X_train.T@X_train)@X_train.T@y_train\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = np.zeros(len(y_test))\n",
    "y_predict = np.round(X_train@w)\n",
    "for i in range(len(y_test)):\n",
    "    success[i] = int(y_train[i] == np.round(y_predict[i]))\n",
    "print('The success rate using least square method for training set is:', sum(success)/len(y_test)*100,'%')    \n",
    "\n",
    "y_predict = np.round(X_test@w)\n",
    "for i in range(len(y_test)):\n",
    "    success[i] = int(y_test[i] == np.round(y_predict[i]))    \n",
    "    \n",
    "print('The success rate using least square method for test  is:', sum(success)/len(y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the equation given in class, we calculated a weight that gives us about 11% accuracy for both training and test data, which is pretty bad. There are 10 classes in the dataset. So essentially our model performs no better than a random guess. One reason of such poor accuracy might the be noise in the data. So we will try PCA model to get rid of the extra noise and see how that affects the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance');\n",
    "print(pca.explained_variance_ratio_.cumsum()[499])\n",
    "print('From the plot we see that the PCA fits the original data pretty well after the number of components reaches 500.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 500) # Only use the first 500 principal components\n",
    "pca.fit(X_train)\n",
    "projected = pca.transform(X_train)\n",
    "print(pca.explained_variance_.shape)\n",
    "print(pca.components_.shape)\n",
    "print(X_train.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = projected\n",
    "w = np.linalg.inv(X_train.T@X_train)@X_train.T@y_train\n",
    "print(w.shape)\n",
    "success = np.zeros(len(y_train))\n",
    "y_predict = np.round(X_train@w)\n",
    "for i in range(len(y_train)):\n",
    "    success[i] = int(y_train[i] == np.round(y_predict[i]))\n",
    "print('The success rate using least square method for training set is:', sum(success)/len(y_test)*100,'%')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA method did not help with the least square case. The success rates are still pretty low. So we will try SVM next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (1000, 3072)\n",
      "Training label shape:  (1000,)\n",
      "Test data shape:  (10000, 3072)\n",
      "Test label shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "names = ['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5']\n",
    "X = np.zeros([50000, 3072])\n",
    "y = np.zeros(50000)\n",
    "for i in range(len(names)):\n",
    "    X[i*10000:(i+1)*10000,:],y[i*10000:(i+1)*10000] = load_batch(names[i])\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test,y_test = load_batch('test_batch')\n",
    "N = 1000\n",
    "X_train = X_train[0:N,:]\n",
    "y_train = y_train[:N]\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training label shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test label shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(probability=False,  kernel=\"poly\", C=1)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The success rate using least square method for training set is: 98.7 %\n"
     ]
    }
   ],
   "source": [
    "y_predict = svc.predict(X_train)\n",
    "success = np.zeros(len(y_train))\n",
    "for i in range(len(y_train)):\n",
    "    success[i] = int(y_train[i] == np.round(y_predict[i]))\n",
    "print('The success rate using least square method for training set is:', sum(success)/len(y_train)*100,'%')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The success rate using least square method for test set is: 32.62 %\n"
     ]
    }
   ],
   "source": [
    "y_predict = svc.predict(X_test)\n",
    "success = np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    success[i] = int(y_test[i] == np.round(y_predict[i]))\n",
    "print('The success rate using least square method for test set is:', sum(success)/len(y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose a subset of size 100 \n",
    "# N = 100\n",
    "# X = data_train\n",
    "# y = labels_train\n",
    "# y[0:10]\n",
    "# i = 1\n",
    "# N = 100\n",
    "# # define cut-off indexes\n",
    "# start_index = i*N\n",
    "# end_index = (i+1)*N\n",
    "# y1 = y[0:start_index]\n",
    "# y2 = y[end_index:]\n",
    "\n",
    "# # extract training data\n",
    "# X_train = np.vstack((X[0:start_index, :], X[end_index:, :]))\n",
    "# y_train = np.hstack((y1,y2))\n",
    "# y_train = y_train.T\n",
    "\n",
    "# # extract validation data\n",
    "# X_val = X[start_index:end_index, :]\n",
    "# y_val = y[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
